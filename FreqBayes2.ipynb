{
 "metadata": {
  "name": "",
  "signature": "sha256:f2369d2196925491b9fb045dadb12b157b4bb8eabf604c159f1ac4d028df8874"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Frequentism and Bayesianism II"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Higher-dimensional Models: Outlier Elimination via Marginalization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So far we've seen two relatively simple problems where Bayesian and frequentist approaches give largely the same result, and in which frequentism is often the simpler method to employ. Here we'll take a look at a Bayesian analysis of a more complicated model in which a frequentist approach is much more difficult to apply.\n",
      "\n",
      "One of the advantages of Bayesianism is that its unified probabilistic framework allows for some really interesting approaches to situations that would be very difficult to treat rigorously within a frequentist framework.\n",
      "\n",
      "For example, let's imagine that we have a set of data which contains some outliers: that is, some number of the data points have errors much larger than those recorded by $e_i$.  We'll take the approach of modeling this via nuisance parameters $\\{g_i\\}$ which lie between 0 and 1, and control whether a point is drawn from the \"true\" error distribution or from a separate \"outlier\" distribution. What's more, we will incorporate the detection of these outliers into the model itself!\n",
      "\n",
      "In this setup, the model is now $(2 + N)$-dimensional:\n",
      "\n",
      "$$ \\theta = [\\mu, \\sigma, g_1, g_2, g_3 \\cdots g_N] $$\n",
      "\n",
      "The expression for the likelihood will look like this:\n",
      "\n",
      "$$\\mathcal{L}(D~|~\\theta) = \\prod_{i=1}^N \\left[ \\frac{g_i}{\\sqrt{2\\pi(\\sigma^2 + e_i^2)}}\\exp\\left(\\frac{-(F_i - \\mu)^2}{2(\\sigma^2 + e_i^2)}\\right) + \\frac{1 - g_i}{\\sqrt{2\\pi\\sigma_\\ast^2}}\\exp\\left(\\frac{-(F_i - \\mu)^2}{2\\sigma_\\ast^2}\\right) \\right]$$\n",
      "\n",
      "So if $g_i = 1$, the point is considered \"good\" data, and if $g_i = 0$, the point is considered \"bad\" data drawn from the distribution with width $\\sigma_\\ast \\gg \\sigma$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(42)  # for reproducibility\n",
      "N = 50\n",
      "mu_true, sigma_true = 1000, 15  # stochastic flux model\n",
      "F_true = stats.norm(mu_true, sigma_true).rvs(N)  # (unknown) true flux\n",
      "F = np.random.normal(F_true, e_true)\n",
      "\n",
      "# Create 10% outliers\n",
      "sigma_star = 500\n",
      "mask = (np.random.random(N) < 0.1)\n",
      "F[mask] += stats.norm(0, sigma_star).rvs(mask.sum())\n",
      "F = np.maximum(F, 0)\n",
      "e = np.sqrt(F)\n",
      "\n",
      "def log_prior(theta):\n",
      "    if np.all(theta[2:] >= 0) and np.all(theta[2:] <= 1):\n",
      "        return 0\n",
      "    else:\n",
      "        return -np.inf\n",
      "    \n",
      "def log_likelihood(theta, F, e, sigma_star):\n",
      "    logP = log_prior(theta)\n",
      "    if np.isneginf(logP):\n",
      "        return logP\n",
      "    g = theta[2:]\n",
      "    logL_1 = (np.log(2 * np.pi * (theta[1] ** 2 + e ** 2))\n",
      "              + (F - theta[0]) ** 2 / (theta[1] ** 2 + e ** 2))\n",
      "    logL_2 = (np.log(2 * np.pi * sigma_star ** 2)\n",
      "              + (F - theta[0]) ** 2 / sigma_star ** 2)\n",
      "    return logP - 0.5 * np.sum(np.logaddexp(logL_1 + np.log(g),\n",
      "                                            logL_2 + np.log(1 - g)))\n",
      "\n",
      "def log_posterior(theta, F, e, sigma_star):\n",
      "    return log_prior(theta) + log_likelihood(theta, F, e, sigma_star)\n",
      "\n",
      "ndim, nwalkers = N + 2, 150\n",
      "nsteps, nburn = 5000, 3000\n",
      "\n",
      "starting_guesses = np.random.rand(nwalkers, ndim)\n",
      "starting_guesses[:, 0] *= 2000\n",
      "starting_guesses[:, 1] *= 20\n",
      "\n",
      "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior,\n",
      "                                args=[F, e, sigma_star])\n",
      "sampler.run_mcmc(starting_guesses, nsteps)\n",
      "sample = sampler.chain  # shape = (nwalkers, nsteps, ndim)\n",
      "sample = sampler.chain[:, nburn:, :].reshape(-1, N + 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'np' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-a293b2d963f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmu_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m  \u001b[0;31m# stochastic flux model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mF_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (unknown) true flux\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}